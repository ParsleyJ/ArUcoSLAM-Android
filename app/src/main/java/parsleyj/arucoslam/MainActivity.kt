package parsleyj.arucoslam

import android.Manifest
import android.content.Intent
import android.content.pm.PackageManager
import android.os.Bundle
//import android.support.v4.app.ActivityCompat
//import android.support.v4.content.ContextCompat
//import android.support.v7.app.AppCompatActivity
import android.util.Log
import android.view.Menu
import android.view.MenuItem
import android.view.SurfaceView
import android.view.WindowManager
import androidx.appcompat.app.AppCompatActivity
import androidx.core.app.ActivityCompat
import androidx.core.content.ContextCompat
import kotlinx.android.synthetic.main.activity_main.*
import org.opencv.android.FixedCameraBridgeViewBase
import org.opencv.android.OpenCVLoader
import org.opencv.core.Mat
import parsleyj.arucoslam.datamodel.*
import parsleyj.arucoslam.datamodel.fixedSpace.MarkerTaggedSpace


class MainActivity : AppCompatActivity(), FixedCameraBridgeViewBase.CvCameraViewListener2 {


    /*
     * general algorithm:
     * (all the subprocedures with names between [] are executed in parallel)
     *
     * [input frame processor]
     * at each frame I:
     *  - detect markers;
     *  - get RTs for each marker pose M;
     *  - select the poses {kM1, kM1, ...} of the markers which are known;
     *  - using the known markers poses {M1, M2, ...}, estimate the pose in S of the phone.
     *  - if the found pose is compliant with the constraints based on the recent history of found poses,
     *       then:
     *      - for each *not-known* marker, compute the its pose in S.
     *      - add the marker with its pose with the "database" of known markers
     *  - if(debug mode) is active, draw the makers and the estimate contributes on a copy I' of the input frame.
     *
     * [position tracker]
     *  It is a kind a non-persisent database about position data of the camera.
     *  It should be "loss-less" in the very recent history (<1-2 secs) and can more "lossy" in less
     *      recent positions history.
     *  Creates a an approximation of the 2d position function (from time to (x,y) pair), using
     *      cubical splines which are updated at each frame.
     *
     * [Track & Map renderer]
     *  Fills a 2d (from above) map image with:
     *      - the pose of the origin in the space S
     *      - the pose of the phone in the space S
     *      - the poses of the found markers
     *      - the path generated by the position tracker
     *
     * [output frame processor]
     *  Iteratively, possibly concurrently, generates a frame which blends
     *      - the input image (returned by the input frame processor, so it could be enriched with debug data)
     *      - the map with path rendered by the Track&Map renderer
     *
     */


    companion object {
        const val TAG = "MainActivity"
        const val CALIBRATION_REQUEST = 1
        const val DETECTED_MARKERS_MAX_OUTPUT = 50
    }

    private val cameraParameters: CalibData by lazy {
        CalibData.xiaomiMiA1RearCamera
    }

    private lateinit var frameStreamProcessor: FrameStreamProcessor<FrameRecyclableData>


    private val markerSpace by lazy {
        MarkerTaggedSpace.singleMarker(
            dictionary = ArucoDictionary.DICT_6X6_250,
            id = 3,
            markerLength = 0.079
        ).toSLAMSpace()
    }

    //TODO do it only when marker space changes.
    private val fixedMarkerIds
        get() = markerSpace.markers
            .map { it.markerId }
            .toIntArray()

    private val fixedMarkerRvects
        get() = markerSpace.markers
            .map { it.pose3d.rotationVector }
            .flattenVecs()
            .toDoubleArray()

    private val fixedMarkerTvects
        get() = markerSpace.markers
            .map { it.pose3d.translationVector }
            .flattenVecs()
            .toDoubleArray()

    private val fixedMarkerConfidences
        get() = markerSpace.markers
            .map {it.markerConfidence }
            .toDoubleArray()

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        window.addFlags(WindowManager.LayoutParams.FLAG_KEEP_SCREEN_ON)
        setContentView(R.layout.activity_main)
        if (ContextCompat.checkSelfPermission(this, Manifest.permission.CAMERA)
            == PackageManager.PERMISSION_DENIED
        ) {
            ActivityCompat.requestPermissions(this, arrayOf(Manifest.permission.CAMERA), 1)
        }
        opencvCamera.visibility = SurfaceView.VISIBLE
        opencvCamera.setCvCameraViewListener(this)
        opencvCamera.setMaxFrameSize(2000, 2000)
    }


    override fun onResume() {
        super.onResume()
        OpenCVLoader.initDebug()
        Log.i(TAG, "OpenCV loaded successfully")
        System.loadLibrary("gnustl_shared")
        System.loadLibrary("native-lib")
        System.loadLibrary("nonfree")
        Log.i(TAG, "NDK Libs loaded successfully")
        opencvCamera.enableView()
    }

    override fun onCreateOptionsMenu(menu: Menu?): Boolean {
        menuInflater.inflate(R.menu.main_menu, menu)
        return true
    }

    override fun onOptionsItemSelected(item: MenuItem) = when (item.itemId) {
        else -> super.onOptionsItemSelected(item)
    }

    private fun setCameraParameters(calibData: CalibData?) {
        val cm = calibData?.cameraMatrix
        val dcs = calibData?.distCoeffs
//        this.cameraParameters = calibData
        Log.i(TAG, "Returned from calibration. cameraMatrix = $cm")
        Log.i(TAG, "Returned from calibration. distCoeffs   = $dcs")
    }

    override fun onActivityResult(requestCode: Int, resultCode: Int, data: Intent?) {
        when (requestCode) {
            CALIBRATION_REQUEST -> {
                setCameraParameters(
                    CalibData.loadCameraParameters(
                        applicationContext
                    )
                )
            }
            else -> {

            }
        }
        super.onActivityResult(requestCode, resultCode, data)
    }

    override fun onCameraViewStarted(width: Int, height: Int) {
//        if (cameraParameters==null) {
//            startActivityForResult(Intent(this, CalibActivity::class.java), CALIBRATION_REQUEST)
//        }
    }

    override fun onCameraViewStopped() {

    }


    private var frameCounter = 0L

    private fun countFrame(): Long {
        return frameCounter++
    }

    data class FrameRecyclableData(
        val foundIDs: IntArray,
        val foundRVecs: DoubleArray,
        val foundTVecs: DoubleArray,
    ) {
        override fun equals(other: Any?): Boolean {
            if (this === other) return true
            if (javaClass != other?.javaClass) return false

            other as FrameRecyclableData

            if (!foundIDs.contentEquals(other.foundIDs)) return false
            if (!foundRVecs.contentEquals(other.foundRVecs)) return false
            if (!foundTVecs.contentEquals(other.foundTVecs)) return false

            return true
        }

        override fun hashCode(): Int {
            var result = foundIDs.contentHashCode()
            result = 31 * result + foundRVecs.contentHashCode()
            result = 31 * result + foundTVecs.contentHashCode()
            return result
        }
    }


    override fun onCameraFrame(inputFrame: FixedCameraBridgeViewBase.CvCameraViewFrame?): Mat? {
        if (inputFrame != null) {
            Log.v(TAG, "inputFrame != null")
            val inputMat = inputFrame.rgba()

            if (!this::frameStreamProcessor.isInitialized) {
                frameStreamProcessor = FrameStreamProcessor(
                    inputMat.size(),
                    inputMat.type(),
                    3, // number of parallel processors on frames
                    instantiateOtherData = { // lambda that tells the FrameStreamProcessor how
                        //  to create a recyclable support data structure
                        FrameRecyclableData(
                            foundIDs = IntArray(DETECTED_MARKERS_MAX_OUTPUT) { 0 },
                            foundRVecs = DoubleArray(DETECTED_MARKERS_MAX_OUTPUT * 3) { 0.0 },
                            foundTVecs = DoubleArray(DETECTED_MARKERS_MAX_OUTPUT * 3) { 0.0 }
                        )
                    }
                ) { inMat, outMat, (foundIDs, foundRvecs, foundTvecs) ->

                    val foundPosesCount = NativeMethods.detectMarkers(
                        cameraParameters.cameraMatrix.nativeObjAddr,
                        cameraParameters.distCoeffs.nativeObjAddr,
                        inMat.nativeObjAddr,
                        outMat.nativeObjAddr,
                        0.079,
                        DETECTED_MARKERS_MAX_OUTPUT,
                        foundIDs,
                        foundRvecs,
                        foundTvecs
                    )


                    if (foundPosesCount > 0) {
                        val estimatedPositionRVec = DoubleArray(3) { 0.0 }
                        val estimatedPositionTVec = DoubleArray(3) { 0.0 }

                        val inliersCount = NativeMethods.estimateCameraPosition(
                            cameraParameters.cameraMatrix.nativeObjAddr, //in
                            cameraParameters.distCoeffs.nativeObjAddr, //in
                            outMat.nativeObjAddr, //in&out
                            fixedMarkerIds, //in
                            fixedMarkerRvects, //in
                            fixedMarkerTvects, //in
                            fixedMarkerConfidences, //in
                            markerSpace.commonLength, //in
                            foundPosesCount, //in
                            foundIDs, //in
                            foundRvecs, //in
                            foundTvecs, //in
                            estimatedPositionRVec, //out
                            estimatedPositionTVec //out
                        )
                    }
                }
            }


            frameStreamProcessor.supply(inputMat, countFrame())
            Log.d(TAG, "FrameStream usage = ${frameStreamProcessor.usage()}")
            return frameStreamProcessor.retrieve()
        } else {
            return null
        }

    }
}





